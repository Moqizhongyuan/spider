# ScrapyTS ğŸ•·ï¸

ä¸€ä¸ªç®€å•æ˜“ç”¨çš„ TypeScript ç½‘ç»œçˆ¬è™«æ¡†æ¶ï¼Œçµæ„Ÿæ¥è‡ª Python çš„ Scrapy æ¡†æ¶ã€‚ä¸“ä¸ºç°ä»£ JavaScript/TypeScript å¼€å‘è€…è®¾è®¡ï¼Œæä¾›äº†æ¸…æ™°çš„æ¶æ„å’Œå¼ºå¤§çš„åŠŸèƒ½ã€‚

## âœ¨ æ¡†æ¶ç‰¹æ€§

- ğŸš€ **TypeScript åŸç”Ÿæ”¯æŒ**ï¼šå®Œæ•´çš„ç±»å‹å®šä¹‰å’Œç¼–è¯‘æ—¶æ£€æŸ¥
- ğŸ•· ï¸**ç±» Scrapy æ¶æ„**ï¼šç†Ÿæ‚‰çš„ Spiderã€Itemã€Pipeline æ¦‚å¿µ
- âš¡ **å¼‚æ­¥å¹¶å‘**ï¼šåŸºäº Promise çš„é«˜æ€§èƒ½å¼‚æ­¥å¤„ç†
- ğŸ”§ **å¯æ‰©å±•ç®¡é“**ï¼šçµæ´»çš„æ•°æ®å¤„ç†ç®¡é“ç³»ç»Ÿ
- ğŸ“Š **å†…ç½®ç»Ÿè®¡**ï¼šè¯·æ±‚ç»Ÿè®¡ã€æˆåŠŸç‡ç›‘æ§
- ğŸ¯ **æ·±åº¦æ§åˆ¶**ï¼šé˜²æ­¢æ— é™é€’å½’çš„æ™ºèƒ½æ·±åº¦ç®¡ç†
- ğŸ’¾ **å¤šç§è¾“å‡ºæ ¼å¼**ï¼šæ”¯æŒ JSONã€TXT ç­‰æ ¼å¼è¾“å‡º

## ğŸ—ï¸ æ¡†æ¶æ¶æ„

```
scrapy/
â”œâ”€â”€ core/                 # æ ¸å¿ƒç»„ä»¶
â”‚   â”œâ”€â”€ item.ts          # æ•°æ®æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ spider.ts        # çˆ¬è™«åŸºç±»
â”‚   â”œâ”€â”€ pipeline.ts      # æ•°æ®å¤„ç†ç®¡é“
â”‚   â””â”€â”€ engine.ts        # çˆ¬è™«å¼•æ“
â”œâ”€â”€ examples/            # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ blog-spider.ts   # åšå®¢çˆ¬è™«ç¤ºä¾‹
â”‚   â””â”€â”€ run-blog-spider.ts # è¿è¡Œè„šæœ¬
â””â”€â”€ index.ts            # æ¡†æ¶å…¥å£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è¿è¡Œç¤ºä¾‹çˆ¬è™«

```bash
# è¿è¡Œåšå®¢çˆ¬è™«ç¤ºä¾‹
npx ts-node scrapy/examples/run-blog-spider.ts
```

### 2. åˆ›å»ºè‡ªå®šä¹‰çˆ¬è™«

```typescript
import { Spider, Response, BlogItem } from "../scrapy";

export class MySpider extends Spider {
  constructor() {
    super("my-spider", ["https://example.com"]);
  }

  async *parse(response: Response) {
    // æå–æ•°æ®
    const title = this.extractTitle(response.text);
    const content = this.extractText(response.text);
    const links = this.extractLinks(response.text);

    // åˆ›å»ºæ•°æ®é¡¹
    yield new BlogItem({
      title,
      content,
      links,
      author: "Unknown",
    });
  }
}
```

### 3. ä½¿ç”¨å¿«é€Ÿå¯åŠ¨å‡½æ•°

```typescript
import { MySpider, runSpider } from "../scrapy";

const spider = new MySpider();
const stats = await runSpider(spider, {
  outputDir: "output",
  outputFormat: "both", // json + text
  concurrent: 4,
  delay: 1,
});
```

## ğŸ“‹ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### Itemï¼ˆæ•°æ®æ¨¡å‹ï¼‰

å®šä¹‰è¦æŠ“å–çš„æ•°æ®ç»“æ„ï¼š

```typescript
export class BlogItem extends Item {
  title?: string;
  author?: string;
  content?: string;
  links?: string[];
  publishDate?: Date;
  tags?: string[];

  validate(): boolean {
    return !!(this.title && this.content);
  }
}
```

### Spiderï¼ˆçˆ¬è™«ï¼‰

æ ¸å¿ƒçˆ¬è™«é€»è¾‘ï¼š

```typescript
export class MySpider extends Spider {
  // èµ·å§‹URL
  constructor() {
    super('spider-name', ['https://example.com']);
  }

  // è§£æå“åº”
  async *parse(response: Response) {
    // è¿”å›Itemæˆ–æ–°çš„Request
    yield new MyItem({ ... });
    yield { url: 'https://example.com/page2' };
  }
}
```

### Pipelineï¼ˆæ•°æ®ç®¡é“ï¼‰

å¤„ç†æŠ“å–çš„æ•°æ®ï¼š

```typescript
export class CustomPipeline extends ItemPipeline {
  async processItem(item: Item, spider: Spider): Promise<Item | null> {
    // æ•°æ®å¤„ç†é€»è¾‘
    if (item.validate()) {
      // ä¿å­˜åˆ°æ•°æ®åº“ã€æ–‡ä»¶ç­‰
      return item;
    }
    return null; // ä¸¢å¼ƒæ— æ•ˆæ•°æ®
  }
}
```

### Engineï¼ˆå¼•æ“ï¼‰

è°ƒåº¦å’Œç®¡ç†çˆ¬è™«ï¼š

```typescript
const engine = new CrawlerEngine({
  concurrentRequests: 8, // å¹¶å‘æ•°
  delay: 1, // è¯·æ±‚é—´éš”(ç§’)
  retryTimes: 2, // é‡è¯•æ¬¡æ•°
  pipelines: [
    // æ•°æ®ç®¡é“
    new ValidationPipeline(),
    new TextWriterPipeline("output"),
  ],
});

await engine.crawl(spider);
```

## ğŸ”§ å†…ç½®ç®¡é“

### ValidationPipeline

éªŒè¯æ•°æ®å®Œæ•´æ€§ï¼Œè¿‡æ»¤æ— æ•ˆæ•°æ®

### DuplicatesPipeline

å»é™¤é‡å¤ URL çš„æ•°æ®é¡¹

### JsonWriterPipeline

å°†æ•°æ®ä¿å­˜ä¸º JSON æ ¼å¼

### TextWriterPipeline

å°†æ•°æ®ä¿å­˜ä¸ºå¯è¯»çš„æ–‡æœ¬æ ¼å¼

## ğŸ“Š æŠ“å–ç»Ÿè®¡

```
çˆ¬è™« blog-spider å®Œæˆç»Ÿè®¡:
- å‘é€è¯·æ±‚: 5
- æ¥æ”¶å“åº”: 5
- æŠ“å–æ•°æ®é¡¹: 5
- ä¸¢å¼ƒæ•°æ®é¡¹: 0
```

## ğŸ¯ æ·±åº¦æ§åˆ¶

æ¡†æ¶å†…ç½®æ·±åº¦æ§åˆ¶ï¼Œé˜²æ­¢æ— é™é€’å½’ï¼š

```typescript
// åœ¨parseæ–¹æ³•ä¸­
const currentDepth = response.request.meta?.depth || 0;
if (currentDepth < maxDepth) {
  yield {
    url: newUrl,
    meta: { depth: currentDepth + 1 }
  };
}
```

## ğŸ“ è¾“å‡ºç¤ºä¾‹

ç”Ÿæˆçš„æ–‡æœ¬æ–‡ä»¶æ ¼å¼ï¼š

```
============================================================
ScrapyTS çˆ¬å–ç»“æœ
çˆ¬è™«åç§°: blog-spider
å¼€å§‹æ—¶é—´: 2025/7/28 15:12:52
============================================================

--- æ•°æ®é¡¹ 2025/7/28 15:12:54 ---
title: Markdownåšå®¢
author: Moqizhongyuan
content: é¡µé¢å†…å®¹...
links: [
  1. https://example.com/link1
  2. https://example.com/link2
]
publishDate: Mon Jul 28 2025 15:12:54 GMT+0800
tags: [
  1. NextJS
  2. TypeScript
]
```

## ğŸ”¥ ä¸åŸç‰ˆ Scrapy å¯¹æ¯”

| ç‰¹æ€§     | ScrapyTS            | Python Scrapy |
| -------- | ------------------- | ------------- |
| è¯­è¨€     | TypeScript          | Python        |
| ç±»å‹å®‰å…¨ | âœ… ç¼–è¯‘æ—¶æ£€æŸ¥       | âŒ è¿è¡Œæ—¶é”™è¯¯ |
| å¼‚æ­¥æ¨¡å‹ | Promise/async-await | Twisted       |
| å­¦ä¹ æ›²çº¿ | ç®€å•ç›´è§‚            | å¤æ‚é…ç½®      |
| å‰ç«¯é›†æˆ | âœ… å¤©ç„¶æ”¯æŒ         | âŒ éœ€è¦æ¡¥æ¥   |
| åŒ…ç®¡ç†   | npm/pnpm            | pip           |

## ğŸ’¡ æœ€ä½³å®è·µ

1. **åˆç†è®¾ç½®å¹¶å‘æ•°**ï¼šé¿å…å¯¹ç›®æ ‡ç½‘ç«™é€ æˆè¿‡å¤§å‹åŠ›
2. **æ·»åŠ è¯·æ±‚å»¶è¿Ÿ**ï¼šæ¨¡æ‹Ÿäººç±»è®¿é—®è¡Œä¸º
3. **æ·±åº¦æ§åˆ¶**ï¼šé¿å…æ— é™é€’å½’æŠ“å–
4. **æ•°æ®éªŒè¯**ï¼šä½¿ç”¨ ValidationPipeline ç¡®ä¿æ•°æ®è´¨é‡
5. **é”™è¯¯å¤„ç†**ï¼šæ•è·å’Œè®°å½•æŠ“å–è¿‡ç¨‹ä¸­çš„é”™è¯¯

## ğŸ› ï¸ æ‰©å±•å¼€å‘

åˆ›å»ºè‡ªå®šä¹‰ç®¡é“ï¼š

```typescript
export class DatabasePipeline extends ItemPipeline {
  async processItem(item: Item) {
    // ä¿å­˜åˆ°æ•°æ®åº“
    await this.saveToDatabase(item);
    return item;
  }

  private async saveToDatabase(item: Item) {
    // æ•°æ®åº“æ“ä½œé€»è¾‘
  }
}
```

## ğŸ“ å¼€å‘è·¯çº¿å›¾

- [ ] æ”¯æŒæ›´å¤šè¾“å‡ºæ ¼å¼ï¼ˆCSVã€XML ç­‰ï¼‰
- [ ] é›†æˆå¸¸ç”¨æ•°æ®åº“è¿æ¥å™¨
- [ ] æ·»åŠ  Web UI æ§åˆ¶é¢æ¿
- [ ] æ”¯æŒåˆ†å¸ƒå¼çˆ¬å–
- [ ] é›†æˆä»£ç†æ± ç®¡ç†
- [ ] æ·»åŠ åçˆ¬è™«ç»•è¿‡æœºåˆ¶

---

ğŸ‰ **ScrapyTS è®© TypeScript ç½‘ç»œçˆ¬è™«å¼€å‘å˜å¾—ç®€å•è€Œå¼ºå¤§ï¼**
